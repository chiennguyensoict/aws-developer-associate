# Simple Storage Service (S3)

S3 is private by default.

- Only the account root user that created the bucket has initial access to the bucket.

S3 Security is controlled via a combination of Identity Policies, Bucket Policies (Resource Policies) and Legacy Bucket and Object ACLs

---

## S3 Bucket Policies

- A Type of **`Resource policy`**
- Just like identity policy but are attached to a bucket instead of identities
- One bucket can have only one bucket policy
- One bucket policy can have multiple statments

### Identity policy limitation

- With identity policy you define what that identity can control.
- Identity policies can only be attached to identities in your own account. So they can control security only inside your account.
- There is no way to provide access to identies outside your own account.

### Resource Perspective permission

- With resource policy you define who can access that resource.
- You can ALLOW/DENY who can access the resource from the same account or from a different account
- Resource policy can define access no matter what the source of access is.
- Resource policy can allow or deny ANONYMOUS principles.
- Resource policy can allow access without even having authentication from AWS.

### Principal

- Resource policy differ from identity policy based on the presense of explicit `Principal` in the bucket policy.
- Principal defines which pricipals are affected by the bucket policy

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicRead",
      "Effect": "Allow",
      "Principal": "*",
      "Action": ["s3:GetObject", "s3:GetObjectVersion"],
      "Resource": ["arn:aws:s3:::DOC-EXAMPLE-BUCKET/*"]
    }
  ]
}
```

- In an identity policy Principal is not defined, as its implied that this policy applies to the principal

### Effective Permission

- If an identity is accessing bucket within the same AWS account, then the effective permission is a combination of all the applicable identity policies and bucket policy.
- If access to bucket is by an anonymous identity, then only bucket policy applies. No identity policy applies.
- If an identity in an external AWS account tries to access the bucket in your account, your bucket policy applies as well all the applicable identity policies in their account.
  - Its a two step process. The external identity should be able to access S3 and your bucket. And your bucket should allow access from the external account.

---

## S3 Access Control Lists (ACL)

This is another form of S3 security. This is now replaced by bucket policies.

- ACL are ways to apply security to object and bucket
- They are inflexible and support only very simple permissions

---

## Block Public Access

Recently S3 have started to block public access to anonymous account by default.

- These settings only applies to anonymous principals
- These settings can be set when you create the bucket or afterwards

Options:

- Block Public Access `(Blocks any public access, no matter what the bucket policy is)`
  - Block public access to buckets and objects granted through _new_ ACL `(Any existing public access granted by existing ACL is allowed. But blocks access granted by new ACL)`
  - Block public access to buckets and objects granted through any access control lists `(Any public access is denied whether enabled before or after block publich access settings were enabled)`
  - Block public access to buckets and objects granted through new public bucket or access point policies `(Any existing public access granted by existing ACL or bucket policies is allowed. But blocks access granted by new ones)`
  - Block public and cross-account access to buckets and objects through any public bucket or access point policies `(Blocks existing or new bucket policies from granting public access)`

---

## Choosing between Identity policy, Bucket Policy and ACL

- If you are granting or denying permission on lots of different resources across an AWS account, use Identity Policies `(Not every resource supports resource policy. Also, you would need resource policy for every service if using resource policy instead.)`
- If you prefer to manage all the permission in one single place then that has to be through IAM. Identity policy would make sense here. `(You can use resource policies at time but use identity policy all the time)`
- If you are only working with one single account, IAM will be able to manage the policies. `(IAM needs to work with identities that you control in your account.)`

- If you want to directly allow external identies or anonymous identities, the use resource policies.
- Never use ACLs, unless you must.

---

# S3 Static Hosting

- Normal access is via AWS APIs. This is done via HTTP call.
- API allows setting up static websites
- Static hosting needs to be enabled while setting the `Index` and `Error` document. Both of them needs to be HTML document.
- When accessing a specific page, it delivers that specific page.
- When you dont specify a page, `Index` page is delivered to you.
- When something goes wrong, `Error` page is delivered.
- AWS creates a `Website Endpoint` from which the assets in the bucket can be accessed using HTTP.
- The endpoint name is choosen based on the:
  - bucket name and
  - region name
- You can use custom domains, only if the bucket name matches with the domain name.

For Static Hosting to work:

- Block Public Access has to be disabled
- The above option alone is not sufficient, as S3 is private by default
- In addition to the above step, you can either select all the objects in the bucket and choose `Make Public`. This would add ACLs to the objects but is not the recommended way
- Instead we can choose to add a Bucket Policy

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicRead",
      "Effect": "Allow",
      "Principal": "*",
      "Action": ["s3:GetObject"],
      "Resource": ["arn:aws:s3:::www.example.com/*"]
    }
  ]
}
```

Static hosting use cases:

- Offloading
- Out-of-band pages

---

## Offloading

Use S3 to deliver any media instead of the compute service.

Delivery via S3 is much cheaper when compared to compute service.

So the compute service can return a HTML page, which references static assets hosted in S3.

---

## Out-of-band pages

If the compute service delivering the HTML pages is under maintainence, it will not let us show any page.

So, under such maintainence phases, we use something called out-of-band pages. These pages are generally used to show status page or the support page.

---

# S3 Pricing

- Storage cost
  - Pricing is based on every GB of data stored
  - And based on every month its stored under S3
- Data Transfer cost
  - Transfer of data into S3 is always free.
  - For every GB of data that you transfer out of S3, there is a cost associated.
  - And price per 1000 requests
- Static hosting charges
  - Every PUT, COPY, POST and LIST is charged per 1000 requests

## Free Tier

As part of the Free Tier:

- 5GB of standard storage is provided
- 20,000 GET requests
- 2,000 PUT requests

---

# S3 Versioning

Versioning is off by default. Once it is turned on, it cannot go back.

- You can only suspend versioning, it cannot be switched off.
- When suspended, old versions still exist. And you will be still billed for them.
- So to save cost you can move the latest version to a new bucket or purge the older versions from the existing bucket.

```

Disabled (Default)  -->  Enabled --> Suspended
                            ^           |
                            |           |
                            |___________|

```

Without versioning an object is solely identified by its key.

```

key = image.jpg
id  = null

```

Versioning lets you store multiple versions of objects within a bucket. Operations which would modify objects, generate a new version.

```

key = image.jpg        -->      key = image.jpg
id  = 111111                    id  = 222222

                                key = image.jpg
                                id  = 111111


```

- Latest Version or Current Version will be returned if no id is specified.

## Deletion with Versioning

When an object is deleted, AWS puts a delete marker on the object and hides all previous versions. You could delete this marker to enable the item.

- To delete an object, you must delete all the versions of that object using their version marker.

```
key = image.jpg                     {Delete Marker}
id  = 222222
                       Delete
key = image.jpg        ------>      key = image.jpg
id  = 111111                        id  = 222222

                                    key = image.jpg
                                    id  = 111111


```

## MFA Delete

Enabled within version configuration in a bucket. This means:

- MFA is required to change bucket versioning state.
- MFA is required to delete versions.
- You pass the serial number (MFA) and the code passed with API calls.

---

# S3 Performance Optimisation

## Single PUT Upload

By default once an object is uploaded`(s3:PutObject)` to S3, it is sent as a single stream of data.

- If a stream fails, the whole upload fails.
- This requires a full restart of the data transfer.

While using Single PUT Upload, you are limited to 5GB data.

## Multipart Upload

Data is broken up into smaller parts.

- We start by breaking down the original blob of data into parts.
- The minimum size of original data should be at least 100MB, to use multipart upload.

Orignal blob can be split into maximum of 10,000 parts.

- Each part can be between 5MB to 5GB
- The last part can be smaller than 5MB

Parts can fail in isolation and be restarted in isolation.

## S3 Transfer Acceleration

While transferring data from one region to another (across geographies), the data has to travel on the public internet before it reaches the public part of AWS network. And using the public internet is not the optimal way of transferring data between destinations.

- To solve this issue we can use S3 Transfer Acceleration.
- This uses AWS Edge Locations. It transfers the data from upload location to the nearest best performing AWS Edge Location.
- The data is then transferred on AWS global network.
- S3 Transfer Acceleration is disabled by default for a bucket.

Restrictions:

- Bucketname cannot contain periods
- Must be DNS compatable in the naming

Transfer acceleration for the S3 bucket needs to be enabled.

- Once enabled, use the `Accelerated Endpoint` for faster data transfers.

---

# S3 Storage Classes

S3 is a **region resillent** service which means it can tolerate the failure of an availability zone.

This is done by replicating objects to at least 3+ AZs when they are uploaded.

---

## S3 Standard

- The default AWS storage class that's used in S3.
- This has 99.999999999% (11, 9's) for Object Durability and 99.99% (4, 9's) for availability.
- Content-MD5 checksums and Cyclic Redundancy Checks are used to detect and fix any data corruption.
- Objects are replicated across at least 3 AZs in an AWS region.
- All of the other storage classes trade some compromises for another.
- Low latency (in milliseconds)

S3 Standard Pricing

- Storage cost
  - Pricing is based on every GB of data stored
  - And based on every month its stored under S3
- Data Transfer cost
  - Transfer of data into S3 is always free.
  - For every GB of data that you transfer out of S3, there is a cost associated.
  - And price per 1000 requests

---

## S3 Standard-IA

Same as S3 Standard

Differences:

- 99.9% availability, slightly lower than standard S3.
- This is approximately 54% cheaper for the base rate.
- Storage Cost
  - Cheaper than S3 standard
- Data Transfer cost
  - Overall cost increases with frequent data access
- Minimum duration charge of 30 days applies
- Minimum object size charged is 128KB (Makes it costly if you have lots of tiny objects)

---

## S3 Standard-IA

Same as S3 Standard-IA

- Doesn't provide multi-AZ resilience model of Standard or Standard-IA.
- Only one AZ is used within the region.
- This has 99.999999999% (11, 9's) for Object Durability unless the AZ fails
- Provides 99.5% availability.
- 80% of the base cost of Standard-IA.

---
